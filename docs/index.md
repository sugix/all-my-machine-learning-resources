title: Home


# Key Concepts


Even though I am a big fan of modern network architectures which creates non-linear boundary in the process of learning data, classical techniques never get old and can still be useful in some scenarios. 

That said, this repository will contain notes, code blocks (notebooks), quizzes and important links which were useful to me when I was revising classic machine learning and deep learning architectures. 

As a XGBoost enthusiast, let me share [Cortado](https://github.com/Statfactory/cortado)

The topics are not limited to following list

- Supervised Learning Techniques
    - Regression - univariate, multiple variable, multivariate
    - Classification - Binary, multi class
    - Decision Trees

- Neural Netoworks
    - Fundamental Neural Network Architecture

- Unsupervised Learning Techniques
    - Clustering
    - Anamoly Detection
    - Recommendation systems
    - Reinforcement learnings

- Other topics
    - Classic Scikit prediction pipelinining
    - Hyperparameter tuning for above
    - Linear models with Scikit Learn
    - Ensemble of models
    - Feature Selection --> Feature Engineering
    - Model evaluation

### Links

- [ML From Scratch](https://github.com/eriklindernoren/ML-From-Scratch/tree/master/mlfromscratch)
- [Ian Goodfellow book](https://www.deeplearningbook.org/)

## Certificates

![Supervised Learning](/Certificates/supervised_certificate.png)
![Advanced Learning](/Certificates/advanced_certificate.png)
![Unsupervised Learning](/Certificates/unsupervised.png)